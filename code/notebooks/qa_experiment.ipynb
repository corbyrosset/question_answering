{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scriptinit\n",
    "import random\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.ifelse import ifelse\n",
    "from models import *\n",
    "from data_import import *\n",
    "from util import *\n",
    "import layers\n",
    "import optimizers\n",
    "from experiment import *\n",
    "from os.path import join\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn on for debugging\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    theano.config.optimizer='fast_compile'\n",
    "    theano.config.exception_verbosity='high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables that don't change between experiments/trials\n",
    "constants = {\n",
    "    'datadir': 'data/',\n",
    "    'glovedir': 'data/glove',\n",
    "    'report_wait': 500,\n",
    "    'save_wait': 1000,\n",
    "    'wv_dimensions': 50,  # speed up learning by using the smallest GloVe dimension\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-me', '--max_epochs'], dest='max_epochs', nargs=None, const=None, default=None, type=<type 'int'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step up argument parsing\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-tn', '--task_number', type=int, required=True)\n",
    "parser.add_argument('-lr', '--base_lr', type=float, required=True)\n",
    "parser.add_argument('-mt', '--model_type', type=str, required=True)\n",
    "parser.add_argument('-hd', '--hidden_dim', type=int, required=True)\n",
    "parser.add_argument('-l2', '--l2_reg', type=float, required=True)\n",
    "\n",
    "parser.add_argument('-lhd', '--lstm_hidden_dim', type=int, required=True)\n",
    "parser.add_argument('-mp', '--mean_pool', type=int, required=True)\n",
    "parser.add_argument('-log', '--logging_path', type=str, required=True)\n",
    "\n",
    "parser.add_argument('-me', '--max_epochs', type=int, required=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variables that change between runs\n",
    "if util.in_ipython():\n",
    "    constants = {\n",
    "        'datadir': '../../data/',\n",
    "        'glovedir': '../../data/glove',\n",
    "        'report_wait': 100,\n",
    "        'save_wait': 1000,\n",
    "        'max_epochs': 100,\n",
    "        'wv_dimensions': 50,  # speed up learning by using the smallest GloVe dimension\n",
    "    }\n",
    "\n",
    "    hyperparams = {\n",
    "        # data and logging\n",
    "        'task_number': 1,  # {1, 3, 5, 17, 19}\n",
    "\n",
    "        # HYPERPARAMETERS\n",
    "        'base_lr': 1e-2,\n",
    "\n",
    "        # all of the models\n",
    "        'model_type': 'sentenceEmbedding',  # one of |sentenceEmbedding| or |averaging|\n",
    "        'hidden_dim': 128,\n",
    "        'l2_reg': 0.0,\n",
    "\n",
    "\n",
    "        # specific to sentence embedding model\n",
    "        'lstm_hidden_dim': 128,\n",
    "        'mean_pool': False,\n",
    "        \n",
    "        'logging_path': 'logging_dir', \n",
    "    }\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "    hyperparams = vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load into namespace and log to metadata\n",
    "for var, val in hyperparams.iteritems():\n",
    "    exec(\"{0} = hyperparams['{0}']\".format(var))\n",
    "    util.metadata(var, val)\n",
    "\n",
    "for var, val in constants.iteritems():\n",
    "    exec(\"{0} = constants['{0}']\".format(var))\n",
    "    util.metadata(var, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_ex, _ = get_data(datadir, task_number, test=False)\n",
    "word_vectors = wordVectors(train_ex)\n",
    "train_ex = examples_to_example_ind(word_vectors, train_ex)  # get examples in numerical format\n",
    "\n",
    "# shuffle data\n",
    "random.shuffle(train_ex)\n",
    "\n",
    "# split the train into 90% train, 10% dev\n",
    "train = train_ex[:int(.9 * len(train_ex))]\n",
    "dev = train_ex[int(.9 * len(train_ex)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cached values for ('../../data/glove', 50)\n"
     ]
    }
   ],
   "source": [
    "# get word_vectors (Using glove for now)\n",
    "wv_matrix = word_vectors.get_wv_matrix(wv_dimensions, glovedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing attention model...\n",
      "Initializing embedding model...\n"
     ]
    }
   ],
   "source": [
    "# initial and setup the attention layer\n",
    "r = 0.001\n",
    "attention_embedding = np.random.rand(hidden_dim, wv_matrix.shape[1]) * 2 * r - r\n",
    "\n",
    "attention_model = attentionModel(embeddings=attention_embedding, lstm_hidden_dim=lstm_hidden_dim)\n",
    "\n",
    "# set up the question + facts -> answer model\n",
    "if model_type == 'averaging':\n",
    "    qa_model = averagingModel(wv_matrix, hidden_dim=hidden_dim, num_classes=wv_matrix.shape[1])\n",
    "elif model_type == 'sentenceEmbedding':\n",
    "    qa_model = embeddingModel(wv_matrix, lstm_hidden_dim=lstm_hidden_dim, nn_hidden_dim=hidden_dim,\n",
    "                            num_classes=wv_matrix.shape[1], mean_pool=mean_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate answer probabilities and predictions\n",
    "support = T.imatrix()\n",
    "mask = T.imatrix()\n",
    "question_idxs = T.ivector()\n",
    "hints = T.ivector()\n",
    "\n",
    "# estimate relevance of each sentence\n",
    "relevance_probs = attention_model.get_relevance_probs(support, mask, question_idxs)\n",
    "\n",
    "def get_word_idxs(relevant_sentence_idxs, support_, mask_):\n",
    "    rel_support = support_[relevant_sentence_idxs, :]\n",
    "    rel_mask = mask_[relevant_sentence_idxs, :]\n",
    "    return rel_support[rel_mask.nonzero()].ravel()\n",
    "\n",
    "# By default, the attention model retrieves any sentence with prob > 0.5 under the model\n",
    "# If no sentence exists, it returns the top two sentences in chronological order\n",
    "max_idxs = T.sort(T.argsort(relevance_probs[:, 1])[-2:])  \n",
    "prob_idxs = T.arange(relevance_probs.shape[0])[T.nonzero(relevance_probs[:, 1] > 0.5)]\n",
    "est_idxs = ifelse(T.lt(T.sum(relevance_probs[:, 1] > 0.5), 1), max_idxs, prob_idxs)\n",
    "\n",
    "\n",
    "# joint training of question model + attention model\n",
    "est_rel_facts = get_word_idxs(est_idxs, support, mask)\n",
    "answer_probs = qa_model.get_answer_probs(est_rel_facts, question_idxs)\n",
    "\n",
    "# train the qa-model using the hints\n",
    "# true_rel_facts = get_word_idxs(hints.nonzero(), support, mask)\n",
    "# answer_probs = qa_model.get_answer_probs(true_rel_facts, question_idxs)\n",
    "\n",
    "# predict without using the hint\n",
    "answer_pred = T.argmax(qa_model.get_answer_probs(est_rel_facts, question_idxs))\n",
    "#answer_pred = T.argmax(qa_model.get_answer_probs(true_rel_facts, question_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the loss and cost function\n",
    "answer = T.iscalar()\n",
    "qa_nll = -T.log(answer_probs)[0, answer]\n",
    "attention_nll = -T.sum(T.log(relevance_probs)[T.arange(hints.shape[0]), hints])\n",
    "loss = qa_nll + attention_nll\n",
    "cost = loss + l2_reg * layers.l2_penalty(qa_model.params + attention_model.params)\n",
    "param_norms = layers.l2_penalty(qa_model.params + attention_model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optimization\n",
    "updates = optimizers.Adagrad(cost, qa_model.params + attention_model.params, base_lr=base_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling predict function\n",
      "Compiling objective function\n",
      "Compiling backprop function\n"
     ]
    }
   ],
   "source": [
    "# compile functions to train and evaluate the model\n",
    "print 'Compiling predict function'\n",
    "qa_model.predict = theano.function(\n",
    "                   inputs = [support, mask, question_idxs],\n",
    "                   outputs = answer_pred)\n",
    "\n",
    "print 'Compiling objective function'\n",
    "qa_model.objective = theano.function(\n",
    "                    inputs = [support, mask, question_idxs, answer, hints],\n",
    "                    outputs = loss)\n",
    "\n",
    "print 'Compiling backprop function'\n",
    "qa_model.backprop = theano.function(\n",
    "                    inputs=[support, mask, question_idxs, answer, hints],\n",
    "                    outputs=[loss, answer_probs, qa_nll, attention_nll],\n",
    "                    updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the experiment object\n",
    "controllers = [BasicController(report_wait=report_wait, save_wait=save_wait, max_epochs=max_epochs, path=logging_path)]\n",
    "\n",
    "dset_samples = len(dev)\n",
    "observers = [ObjectiveObserver(dset_samples=dset_samples, report_wait=report_wait),\n",
    "             AccuracyObserver(dset_samples=dset_samples, report_wait=report_wait)]\n",
    "\n",
    "experiment = Experiment(qa_model, train, dev, controllers=controllers, observers=observers, path=logging_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent: Examples 900 \n",
      "steps: 0, epochs: 0.00\n",
      "objective.dev: 4.637, objective.train: 4.437, accuracy.train: 0.140, accuracy.dev: 0.160\n",
      "66 of 900 processed (5.05909514427 s)\n",
      "steps: 100, epochs: 0.00\n",
      "objective.dev: 4.090, objective.train: 3.687, accuracy.train: 0.590, accuracy.dev: 0.530\n",
      "131 of 900 processed (10.0901651382 s)\n",
      "steps: 200, epochs: 0.00\n",
      "objective.dev: 3.875, objective.train: 3.948, accuracy.train: 0.680, accuracy.dev: 0.560\n",
      "201 of 900 processed (15.4355690479 s)\n",
      "steps: 300, epochs: 0.00\n",
      "objective.dev: 3.834, objective.train: 3.486, accuracy.train: 0.600, accuracy.dev: 0.530\n",
      "301 of 900 processed (22.2356929779 s)\n",
      "steps: 400, epochs: 0.00\n",
      "objective.dev: 3.612, objective.train: 3.398, accuracy.train: 0.650, accuracy.dev: 0.610\n",
      "401 of 900 processed (28.9022572041 s)\n",
      "496 of 900 processed (33.9209890366 s)\n",
      "steps: 500, epochs: 0.00\n",
      "objective.dev: 3.414, objective.train: 3.185, accuracy.train: 0.710, accuracy.dev: 0.700\n",
      "556 of 900 processed (38.9249300957 s)\n",
      "steps: 600, epochs: 0.00\n",
      "objective.dev: 3.459, objective.train: 3.167, accuracy.train: 0.660, accuracy.dev: 0.630\n",
      "621 of 900 processed (43.9461450577 s)\n",
      "steps: 700, epochs: 0.00\n",
      "objective.dev: 3.309, objective.train: 3.185, accuracy.train: 0.760, accuracy.dev: 0.700\n",
      "701 of 900 processed (49.8041470051 s)\n",
      "790 of 900 processed (54.8088951111 s)\n",
      "steps: 800, epochs: 0.00\n",
      "objective.dev: 3.251, objective.train: 3.401, accuracy.train: 0.780, accuracy.dev: 0.700\n",
      "856 of 900 processed (59.8244171143 s)\n",
      "steps: 900, epochs: 1.00\n",
      "objective.dev: 3.238, objective.train: 3.016, accuracy.train: 0.690, accuracy.dev: 0.680\n",
      "64 of 900 processed (5.00249218941 s)\n",
      "steps: 1000, epochs: 1.00\n",
      "saving params...\n",
      "Saving params to  logging_dir/params.cpkl\n",
      "objective.dev: 3.200, objective.train: 2.855, accuracy.train: 0.710, accuracy.dev: 0.690\n",
      "120 of 900 processed (10.0231389999 s)\n",
      "steps: 1100, epochs: 1.00\n",
      "objective.dev: 3.249, objective.train: 3.063, accuracy.train: 0.790, accuracy.dev: 0.670\n",
      "201 of 900 processed (15.9082269669 s)\n",
      "steps: 1200, epochs: 1.00\n",
      "objective.dev: 3.111, objective.train: 2.788, accuracy.train: 0.740, accuracy.dev: 0.750\n",
      "301 of 900 processed (22.6496729851 s)\n"
     ]
    }
   ],
   "source": [
    "# launch the experiment\n",
    "experiment.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plot learning curves\n",
    "#report(join(logging_path, 'history.cpkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
