{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scriptinit\n",
    "import random\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from models import *\n",
    "from data_import import *\n",
    "from util import *\n",
    "import layers\n",
    "import optimizers\n",
    "from experiment import *\n",
    "from os.path import join\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn on for debugging\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    theano.config.optimizer='fast_compile'\n",
    "    theano.config.exception_verbosity='high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables that don't change between experiments/trials\n",
    "constants = {\n",
    "    'datadir': 'data/',\n",
    "    'glovedir': 'data/glove',\n",
    "    'report_wait': 500,\n",
    "    'save_wait': 1000,\n",
    "    'wv_dimensions': 50,  # speed up learning by using the smallest GloVe dimension\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-me', '--max_epochs'], dest='max_epochs', nargs=None, const=None, default=None, type=<type 'int'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step up argument parsing\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-tn', '--task_number', type=int, required=True)\n",
    "parser.add_argument('-lr', '--base_lr', type=float, required=True)\n",
    "parser.add_argument('-mt', '--model_type', type=str, required=True)\n",
    "parser.add_argument('-hd', '--hidden_dim', type=int, required=True)\n",
    "parser.add_argument('-l2', '--l2_reg', type=float, required=True)\n",
    "\n",
    "parser.add_argument('-lhd', '--lstm_hidden_dim', type=int, required=True)\n",
    "parser.add_argument('-mp', '--mean_pool', type=int, required=True)\n",
    "parser.add_argument('-log', '--logging_path', type=str, required=True)\n",
    "\n",
    "parser.add_argument('-me', '--max_epochs', type=int, required=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variables that change between runs\n",
    "if util.in_ipython():\n",
    "    constants = {\n",
    "        'datadir': '../../data/',\n",
    "        'glovedir': '../../data/glove',\n",
    "        'report_wait': 100,\n",
    "        'save_wait': 1000,\n",
    "        'max_epochs': 50,\n",
    "        'wv_dimensions': 50,  # speed up learning by using the smallest GloVe dimension\n",
    "    }\n",
    "\n",
    "    hyperparams = {\n",
    "        # data and logging\n",
    "        'task_number': 1,  # {1, 3, 5, 17, 19}\n",
    "\n",
    "        # HYPERPARAMETERS\n",
    "        'base_lr': 1e-3,\n",
    "\n",
    "        # all of the models\n",
    "        'model_type': 'sentenceEmbedding',  # one of |sentenceEmbedding| or |averaging|\n",
    "        'hidden_dim': 128,\n",
    "        'l2_reg': 1e-4,\n",
    "\n",
    "\n",
    "        # specific to sentence embedding model\n",
    "        'lstm_hidden_dim': 128,\n",
    "        'mean_pool': False,\n",
    "        \n",
    "        'logging_path': 'logging_dir', \n",
    "    }\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "    hyperparams = vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load into namespace and log to metadata\n",
    "for var, val in hyperparams.iteritems():\n",
    "    exec(\"{0} = hyperparams['{0}']\".format(var))\n",
    "    util.metadata(var, val)\n",
    "\n",
    "for var, val in constants.iteritems():\n",
    "    exec(\"{0} = constants['{0}']\".format(var))\n",
    "    util.metadata(var, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cached values for ('../../data/qa1_single-supporting-fact_train.txt',)\n",
      "loading cached values for ('../../data/qa1_single-supporting-fact_test.txt',)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "train_ex, _ = get_data(datadir, task_number, test=False)\n",
    "word_vectors = wordVectors(train_ex)\n",
    "train_ex = examples_to_example_ind(word_vectors, train_ex)  # get examples in numerical format\n",
    "\n",
    "# shuffle data\n",
    "random.shuffle(train_ex)\n",
    "\n",
    "# split the train into 90% train, 10% dev\n",
    "train = train_ex[:int(.9 * len(train_ex))]\n",
    "dev = train_ex[int(.9 * len(train_ex)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cached values for ('../../data/glove', 50)\n"
     ]
    }
   ],
   "source": [
    "# get word_vectors (Using glove for now)\n",
    "wv_matrix = word_vectors.get_wv_matrix(wv_dimensions, glovedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing attention model...\n",
      "Initializing embedding model...\n"
     ]
    }
   ],
   "source": [
    "# initial and setup the attention layer\n",
    "r = 0.001\n",
    "attention_embedding = np.random.rand(hidden_dim, wv_matrix.shape[1]) * 2 * r - r\n",
    "\n",
    "attention_model = attentionModel(embeddings=attention_embedding, lstm_hidden_dim=lstm_hidden_dim, reverse=True)\n",
    "\n",
    "# set up the question + facts -> answer model\n",
    "if model_type == 'averaging':\n",
    "    qa_model = averagingModel(wv_matrix, hidden_dim=hidden_dim, num_classes=wv_matrix.shape[1])\n",
    "elif model_type == 'sentenceEmbedding':\n",
    "    qa_model = embeddingModel(wv_matrix, lstm_hidden_dim=lstm_hidden_dim, nn_hidden_dim=hidden_dim,\n",
    "                            num_classes=wv_matrix.shape[1], mean_pool=mean_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate answer probabilities and predictions\n",
    "support = T.imatrix()\n",
    "mask = T.imatrix()\n",
    "question_idxs = T.ivector()\n",
    "hints = T.ivector()\n",
    "\n",
    "# estimate relevance of each sentence\n",
    "relevance_probs = attention_model.get_relevance_probs(support, mask, question_idxs)\n",
    "\n",
    "# train the qa-model using the hints\n",
    "answer_probs = qa_model.get_answer_probs(support[hints.nonzero(), :], mask[hints.nonzero(), :], question_idxs)\n",
    "\n",
    "# predict without using the hint\n",
    "relevant_sentences = support[relevance_probs[:, 1] > 0.5, :]\n",
    "relevant_mask = mask[relevance_probs[:, 1] > 0.5, :]\n",
    "answer_pred = T.argmax(qa_model.get_answer_probs(relevant_sentences, relevant_mask, question_idxs))\n",
    "#answer_pred = T.argmax(qa_model.get_answer_probs(support[hints.nonzero(), :], mask[hints.nonzero(), :], question_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the loss and cost function\n",
    "answer = T.ivector()\n",
    "loss = -T.mean(T.log(answer_probs)[T.arange(answer.shape[0]), answer]) - T.mean(T.log(relevance_probs)[T.arange(hints.shape[0]), hints])\n",
    "cost = loss + l2_reg * layers.l2_penalty(qa_model.params + attention_model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optimization\n",
    "updates = optimizers.Adagrad(cost, qa_model.params, base_lr=base_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling predict function\n",
      "Compiling objective function\n",
      "Compiling backprop function\n"
     ]
    }
   ],
   "source": [
    "# compile functions to train and evaluate the model\n",
    "print 'Compiling predict function'\n",
    "qa_model.predict = theano.function(\n",
    "                   inputs = [support, mask, question_idxs],\n",
    "                   outputs = answer_pred)\n",
    "\n",
    "print 'Compiling objective function'\n",
    "qa_model.objective = theano.function(\n",
    "                    inputs = [support, mask, question_idxs, answer, hints],\n",
    "                    outputs = loss)\n",
    "\n",
    "print 'Compiling backprop function'\n",
    "qa_model.backprop = theano.function(\n",
    "                    inputs=[support, mask, question_idxs, answer, hints],\n",
    "                    outputs=[loss, answer_probs],\n",
    "                    updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the experiment object\n",
    "controllers = [BasicController(report_wait=report_wait, save_wait=save_wait, max_epochs=max_epochs, path=logging_path)]\n",
    "\n",
    "dset_samples = len(dev)\n",
    "observers = [ObjectiveObserver(dset_samples=dset_samples, report_wait=report_wait),\n",
    "             AccuracyObserver(dset_samples=dset_samples, report_wait=report_wait)]\n",
    "\n",
    "experiment = Experiment(qa_model, train, dev, controllers=controllers, observers=observers, path=logging_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent: Examples 900 \n",
      "steps: 0, epochs: 0.00\n",
      "objective.dev: 3.741, objective.train: 3.740, accuracy.train: 0.000, accuracy.dev: 0.000\n",
      "57 of 900 processed (5.02354383469 s)\n",
      "steps: 100, epochs: 0.00\n",
      "objective.dev: 2.738, objective.train: 2.579, accuracy.train: 0.120, accuracy.dev: 0.070\n",
      "114 of 900 processed (10.0445899963 s)\n",
      "steps: 200, epochs: 0.00\n",
      "objective.dev: 2.495, objective.train: 2.501, accuracy.train: 0.230, accuracy.dev: 0.250\n",
      "201 of 900 processed (16.2485368252 s)\n",
      "steps: 300, epochs: 0.00\n",
      "objective.dev: 2.418, objective.train: 2.474, accuracy.train: 0.110, accuracy.dev: 0.250\n",
      "301 of 900 processed (23.231678009 s)\n"
     ]
    }
   ],
   "source": [
    "# launch the experiment\n",
    "experiment.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plot learning curves\n",
    "#report(join(logging_path, 'history.cpkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
