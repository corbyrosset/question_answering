{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scriptinit\n",
    "import random\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from models import *\n",
    "from data_import import *\n",
    "from util import *\n",
    "import layers\n",
    "import optimizers\n",
    "from experiment import *\n",
    "from os.path import join\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn on for debugging\n",
    "DEBUG = True\n",
    "if DEBUG:\n",
    "    theano.config.optimizer='fast_compile'\n",
    "    theano.config.exception_verbosity='high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables that don't change between experiments/trials\n",
    "constants = {\n",
    "    'datadir': 'data/',\n",
    "    'glovedir': 'data/glove',\n",
    "    'report_wait': 500,\n",
    "    'save_wait': 1000,\n",
    "    'max_epochs': 50,\n",
    "    'wv_dimensions': 50,  # speed up learning by using the smallest GloVe dimension\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-log', '--logging_path'], dest='logging_path', nargs=None, const=None, default=None, type=<type 'str'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step up argument parsing\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-tn', '--task_number', type=int, required=True)\n",
    "parser.add_argument('-lr', '--base_lr', type=float, required=True)\n",
    "parser.add_argument('-mt', '--model_type', type=str, required=True)\n",
    "parser.add_argument('-hd', '--hidden_dim', type=int, required=True)\n",
    "parser.add_argument('-l2', '--l2_reg', type=float, required=True)\n",
    "\n",
    "parser.add_argument('-lhd', '--lstm_hidden_dim', type=int, required=True)\n",
    "parser.add_argument('-mp', '--mean_pool', type=int, required=True)\n",
    "parser.add_argument('-log', '--logging_path', type=str, required=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variables that change between runs\n",
    "if util.in_ipython():\n",
    "    constants = {\n",
    "        'datadir': '../../data/',\n",
    "        'glovedir': '../../data/glove',\n",
    "        'report_wait': 500,\n",
    "        'save_wait': 1000,\n",
    "        'max_epochs': 50,\n",
    "        'wv_dimensions': 50,  # speed up learning by using the smallest GloVe dimension\n",
    "    }\n",
    "\n",
    "    hyperparams = {\n",
    "        # data and logging\n",
    "        'task_number': 1,  # {1, 3, 5, 17, 19}\n",
    "\n",
    "        # HYPERPARAMETERS\n",
    "        'base_lr': 1e-2,\n",
    "\n",
    "        # all of the models\n",
    "        'model_type': 'sentenceEmbedding',  # one of |sentenceEmbedding| or |averaging|\n",
    "        'hidden_dim': 128,\n",
    "        'l2_reg': 0.0,\n",
    "\n",
    "\n",
    "        # specific to sentence embedding model\n",
    "        'lstm_hidden_dim': 128,\n",
    "        'mean_pool': False,\n",
    "        \n",
    "        'logging_path': 'logging_dir', \n",
    "    }\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "    hyperparams = vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load into namespace and log to metadata\n",
    "for var, val in hyperparams.iteritems():\n",
    "    exec(\"{0} = hyperparams['{0}']\".format(var))\n",
    "    util.metadata(var, val)\n",
    "\n",
    "for var, val in constants.iteritems():\n",
    "    exec(\"{0} = constants['{0}']\".format(var))\n",
    "    util.metadata(var, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_ex, _ = get_data(datadir, task_number, test=False)\n",
    "word_vectors = wordVectors(train_ex)\n",
    "train_ex = examples_to_example_ind(word_vectors, train_ex)  # get examples in numerical format\n",
    "\n",
    "# shuffle data\n",
    "random.shuffle(train_ex)\n",
    "\n",
    "# split the train into 90% train, 10% dev\n",
    "train = train_ex[:int(.9 * len(train_ex))]\n",
    "dev = train_ex[int(.9 * len(train_ex)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading glove vectors\n",
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "120000\n",
      "140000\n",
      "160000\n",
      "180000\n",
      "200000\n",
      "220000\n",
      "240000\n",
      "260000\n",
      "280000\n",
      "300000\n",
      "320000\n",
      "340000\n",
      "360000\n",
      "380000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# get word_vectors (Using glove for now)\n",
    "wv_matrix = word_vectors.get_wv_matrix(wv_dimensions, glovedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing attention model...\n",
      "Initializing embedding model...\n"
     ]
    }
   ],
   "source": [
    "# initial and setup the attention layer\n",
    "r = 0.001\n",
    "attention_embedding = np.random.rand(hidden_dim, wv_matrix.shape[1]) * 2 * r - r\n",
    "\n",
    "attention_model = attentionModel(embeddings=attention_embedding, lstm_hidden_dim=lstm_hidden_dim, reverse=True)\n",
    "\n",
    "# set up the question + facts -> answer model\n",
    "if model_type == 'averaging':\n",
    "    qa_model = averagingModel(wv_matrix, hidden_dim=hidden_dim, num_classes=wv_matrix.shape[1])\n",
    "elif model_type == 'sentenceEmbedding':\n",
    "    qa_model = embeddingModel(wv_matrix, lstm_hidden_dim=lstm_hidden_dim, nn_hidden_dim=hidden_dim,\n",
    "                            num_classes=wv_matrix.shape[1], mean_pool=mean_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate answer probabilities and predictions\n",
    "support = T.imatrix()\n",
    "mask = T.imatrix()\n",
    "question_idxs = T.ivector()\n",
    "hints = T.ivector()\n",
    "\n",
    "# estimate relevance of each sentence\n",
    "relevance_probs = attention_model.get_relevance_probs(support, mask, question_idxs)\n",
    "\n",
    "# train the qa-model using the hints\n",
    "answer_probs = qa_model.get_answer_probs(support[hints > 0, :], mask[hints > 0, :], question_idxs)\n",
    "\n",
    "# predict without using the hint\n",
    "relevant_sentences = support[relevance_probs[:, 1] > 0.5, :]\n",
    "relevant_mask = mask[relevance_probs[:, 1] > 0.5, :]\n",
    "answer_pred = T.argmax(qa_model.get_answer_probs(relevant_sentences, relevant_mask, question_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the loss and cost function\n",
    "answer = T.ivector()\n",
    "loss = -T.mean(T.log(answer_probs)[T.arange(answer.shape[0]), answer]) - T.mean(T.log(relevance_probs)[T.arange(hints.shape[0]), hints])\n",
    "cost = loss + l2_reg * layers.l2_penalty(qa_model.params + attention_model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optimization\n",
    "updates = optimizers.Adagrad(cost, qa_model.params, base_lr=base_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.gof.compilelock): Overriding existing lock by dead process '14258' (I am process '16042')\n",
      "WARNING:theano.gof.compilelock:Overriding existing lock by dead process '14258' (I am process '16042')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling predict function\n",
      "Compiling objective function\n",
      "Compiling backprop function\n"
     ]
    }
   ],
   "source": [
    "# compile functions to train and evaluate the model\n",
    "print 'Compiling predict function'\n",
    "qa_model.predict = theano.function(\n",
    "                   inputs = [support, mask, question_idxs],\n",
    "                   outputs = answer_pred)\n",
    "\n",
    "print 'Compiling objective function'\n",
    "qa_model.objective = theano.function(\n",
    "                    inputs = [support, mask, question_idxs, answer, hints],\n",
    "                    outputs = loss)\n",
    "\n",
    "print 'Compiling backprop function'\n",
    "qa_model.backprop = theano.function(\n",
    "                    inputs=[support, mask, question_idxs, answer, hints],\n",
    "                    outputs=[loss, answer_probs],\n",
    "                    updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up the experiment object\n",
    "controllers = [BasicController(report_wait=report_wait, save_wait=save_wait, max_epochs=max_epochs, path=logging_path)]\n",
    "\n",
    "dset_samples = len(dev)\n",
    "observers = [ObjectiveObserver(dset_samples=dset_samples, report_wait=report_wait),\n",
    "             AccuracyObserver(dset_samples=dset_samples, report_wait=report_wait)]\n",
    "\n",
    "experiment = Experiment(qa_model, train, dev, controllers=controllers, observers=observers, path=logging_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent: Examples 25 \n",
      "steps: 0, epochs: 0.00\n",
      "objective.dev: 2.719, objective.train: 2.455, accuracy.train: 0.400, accuracy.dev: 0.000"
     ]
    }
   ],
   "source": [
    "# launch the experiment\n",
    "experiment.run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plot learning curves\n",
    "report(join(logging_path, 'history.cpkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
