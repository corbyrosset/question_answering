{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import DataImport\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input: examples, an array of examples, each a dict containing:\n",
    "# example['s']: an array of sentences corresponding to statements \n",
    "# potentially helpful in solving the problem\n",
    "# example['q']: the question asked\n",
    "# example['a']: the answer of the question\n",
    "#\n",
    "# Output: arrays of strings corresponding to inputs for a bag of \n",
    "# words feature extractor. X are statements, Y is answers, and Q are questions.\n",
    "def make_strings(examples):\n",
    "    X = []\n",
    "    Y = []\n",
    "    Q = []\n",
    "    for example in examples:\n",
    "        X.append(\" \".join(example['s']))\n",
    "        Q.append(example['q'])\n",
    "        Y.append(example['a'])\n",
    "    print \"Examples loaded: \"\n",
    "    print \"\\t X[1] = %s\\n\\t Y[1] = %s\\n\\t Q[1] = %s\" % (X[1], Y[1], Q[1]) \n",
    "    return (X,Y,Q)\n",
    "\n",
    "# Runs a given bag of words feature extractor feat_ex on inputs X, Y and Q\n",
    "# from make_strings. Returns (T, Q), where T is a stack of the supporting\n",
    "# statement (X) and question (Q) vectors, and Y is a matrix of answer vectors.\n",
    "def get_features(feat_ex, X, Y, Q):\n",
    "    X_t = feat_ex.transform(X)\n",
    "    Q_t = feat_ex.transform(Q)\n",
    "    Y_t = np.argmax(feat_ex.transform(Y).todense(), axis=1)\n",
    "    return (hstack([X_t, Q_t]), Y_t)\n",
    "\n",
    "def fix_directions(examples):\n",
    "    directions = {'n':'north','e':'east','s':'south','w':'west'}\n",
    "    for example in examples:\n",
    "        dirs = example['a'].split(',')\n",
    "        newdirs = [directions[d] for d in dirs]\n",
    "        example['a'] = \" \".join(newdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples loaded: \n",
      "\t X[1] = The bedroom is west of the hallway. The office is east of the garden. The garden is north of the kitchen. The kitchen is north of the bathroom. The hallway is west of the garden.\n",
      "\t Y[1] = north west\n",
      "\t Q[1] = How do you go from the kitchen to the hallway?\n",
      "Examples loaded: \n",
      "\t X[1] = The hallway is west of the bathroom. The office is south of the bedroom. The garden is north of the bedroom. The kitchen is east of the bedroom. The hallway is east of the kitchen.\n",
      "\t Y[1] = east east\n",
      "\t Q[1] = How do you go from the bedroom to the hallway?\n"
     ]
    }
   ],
   "source": [
    "datadir = \"./data/\"\n",
    "tasknum = 19\n",
    "if tasknum == 1:\n",
    "    train_examples = DataImport.getdata(datadir+\"qa1_single-supporting-fact_train.txt\")\n",
    "    test_examples = DataImport.getdata(datadir+\"qa1_single-supporting-fact_test.txt\")\n",
    "elif tasknum == 5:\n",
    "    train_examples = DataImport.getdata(datadir+\"qa5_three-arg-relations_train.txt\")\n",
    "    test_examples = DataImport.getdata(datadir+\"qa5_three-arg-relations_test.txt\")\n",
    "elif tasknum == 7:\n",
    "    train_examples = DataImport.getdata(datadir+\"qa7_counting_train.txt\")\n",
    "    test_examples = DataImport.getdata(datadir+\"qa7_counting_test.txt\")\n",
    "elif tasknum == 17:\n",
    "    train_examples = DataImport.getdata(datadir+\"qa17_positional-reasoning_train.txt\")\n",
    "    test_examples = DataImport.getdata(datadir+\"qa17_positional-reasoning_test.txt\")\n",
    "elif tasknum == 19:\n",
    "    train_examples = DataImport.getdata(datadir+\"qa19_path-finding_train.txt\")\n",
    "    test_examples = DataImport.getdata(datadir+\"qa19_path-finding_test.txt\")\n",
    "    # hack to replace directions with their actual words to fit bag of words model\n",
    "    fix_directions(train_examples)\n",
    "    fix_directions(test_examples)\n",
    "\n",
    "# Create ngram vectorizer and string inputs\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 4),min_df=1)\n",
    "(X_tr, Y_tr, Q_tr) = make_strings(train_examples)\n",
    "(X_te, Y_te, Q_te) = make_strings(test_examples)\n",
    "\n",
    "# Want the feature space to include the words in the test examples too\n",
    "feature_extractor = vectorizer.fit(X_tr+X_te+Y_tr+Y_te+Q_tr+Q_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtain featurized vector stacks \n",
    "(t_train, y_train) = get_features(feature_extractor, X_tr, Y_tr, Q_tr)\n",
    "print t_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "clf.fit(t_train, y_train)\n",
    "print \"Train score: %f\" % clf.score(t_train, y_train)\n",
    "\n",
    "(t_test, y_test) = get_features(feature_extractor, X_te, Y_te, Q_te)\n",
    "print \"Test score: %f\" % clf.score(t_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
